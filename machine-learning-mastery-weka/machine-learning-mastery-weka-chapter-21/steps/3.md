Machine learning algorithms can be configured to elicit different behavior. This is useful because
it allows their behavior to be adapted to the specifics of your machine learning problem. This
is also a difficulty because you must choose how to configure an algorithm without knowing
beforehand which configuration is best for your problem. Because of this, you must tune the
configuration parameters of each machine learning algorithm to your problem. This is often
called algorithm tuning or algorithm hyperparameter optimization. It is an empirical process of
trial and error.

You can tinker with an algorithm in order to discover the combination of parameters that
result in the best performance for your problem, but this can be difficult because you must
record all of the results and compare them manually. A more robust approach is to design a
controlled experiment to evaluate a number of predefined algorithm configurations and provide
tools to review compare the results. The Weka Experiment Environment provides an interface
that allows you to design, execute and analyze the results from these types of experiments.