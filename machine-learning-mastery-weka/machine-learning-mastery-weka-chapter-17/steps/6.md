Naive Bayes is a classification algorithm. Traditionally it assumes that the input values are
nominal, although numerical inputs are supported by assuming a distribution. Naive Bayes
uses a simple implementation of Bayes Theorem (hence naive) where the prior probability for
each class is calculated from the training data and assumed to be independent of each other
(technically called conditionally independent).

This is an unrealistic assumption because we expect the variables to interact and be dependent,
although this assumption makes the probabilities fast and easy to calculate. Even under this
unrealistic assumption, Naive Bayes has been shown to be a very effective classification algorithm.
Naive Bayes calculates the posterior probability for each class and makes a prediction for the
class with the highest probability. As such, it supports both binary classification and multiclass
classification problems. Choose the Naive Bayes algorithm:

1. Click the Choose button and select NaiveBayes under the bayes group
2. Click on the name of the algorithm to review the algorithm configuration

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-17/steps/images/81.png)
