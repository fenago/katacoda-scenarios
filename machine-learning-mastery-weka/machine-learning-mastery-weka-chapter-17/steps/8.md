Decision trees can support classification and regression problems. Decision trees are more
recently referred to as Classification And Regression Trees (CART). They work by creating a
tree to evaluate an instance of data. The tree is inverted, starting at the top or root of the
tree and moving down to the leaves until a prediction can be made. The process of creating a
decision tree works by greedily selecting the best split point in order to make predictions and
repeating the process until the tree is a fixed depth. After the tree is constructed, it is pruned
in order to improve the modelâ€™s ability to generalize to new data. Choose the decision tree
algorithm:

1. Click the Choose button and select REPTree under the trees group
2. Click on the name of the algorithm to review the algorithm configuration

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-17/steps/images/83.png)

