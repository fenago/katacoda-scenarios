The size of the neighborhood is controlled by the k parameter, called IBk in Weka. For
example, if set to 1, then predictions are made using the single most similar training instance to
a given new pattern for which a prediction is requested. Common values for k are 3, 7, 11 and
21, larger for larger dataset sizes. Weka can automatically discover a good value for k using
cross-validation inside the algorithm by setting the crossValidate parameter to True.

Another important parameter is the distance measure used. This is configured in the
nearestNeighbourSearchAlgorithm which controls the way in which the training data is stored
and searched. The default is a LinearNNSearch. Clicking the name of this search algorithm will
provide another configuration window where you can choose a distanceFunction parameter. By
default, Euclidean distance is used to calculate the distance between instances, which is good
for numerical data with the same scale. Manhattan distance is good to use if your attributes
differ in measures or type. It is a good idea to try a suite of different k values and distance
measures on your problem and see what works best.

1) Click OK to close the algorithm configuration
2) Click the Start button to run the algorithm on the Boston house price dataset
You can see that with the default configuration that KNN algorithm achieves an RMSE of
46

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-18/steps/images/94.png)
