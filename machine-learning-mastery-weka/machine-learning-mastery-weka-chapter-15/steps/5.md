Given that there are four different test options to choose from, which one should you use? Each
test option has a time and place, summarized as follows:
- **Training Dataset:** Only to be used when you have all of the data and you are interested
in creating a descriptive rather than a predictive model. Because you have all of the data,
you do not need to make new predictions. You are interested in creating a model to better
understand the problem.
- **Supplied Test Set:** When the data is very large, e.g. millions of records and you do not
need all of it to train a model. Also useful when the test set has been defined by a third
party.
- **Percentage Split:** Excellent to use to get a quick idea of the performance of a model.
Not to be used to make decisions, unless you have a very large dataset and are confident
(e.g. you have tested) that the splits sufficiently describe the problem. A common split
value is 66% to 34% for train and test sets respectively.
- **Cross-Validation:** The default. To be used when you are unsure. Generally provides
a more accurate estimate of the performance than the other techniques. Not to be used
when you have a very large data. Common values for k are 5 and 10, depending on the
size of the dataset.
If in doubt, use k-fold cross-validation where k is set to 10.