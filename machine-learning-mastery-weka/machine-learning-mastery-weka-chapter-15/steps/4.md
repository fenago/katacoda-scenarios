
**Percentage Split**

Randomly split your dataset into a training and a testing partitions each time you evaluate a
model. This can give you a very quick estimate of performance and like using a supplied test
set, is preferable only when you have a large dataset.

**Cross-Validation**

Split the dataset into k-partitions or folds. Train a model on all of the partitions except one
that is held out as the test set, then repeat this process creating k-different models and give
each fold a chance of being held out as the test set. Then calculate the average performance of
all k-models. This is the gold standard for evaluating model performance, but has the cost of
creating many more models.
You can see these techniques in the Weka Explorer on the Classify tab after you have loaded
a dataset.

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-15/steps/images/74.png)