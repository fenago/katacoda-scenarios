When evaluating a machine learning algorithm on a classification problem, you are given a vast
amount of performance information to digest This is because classification may be the most
studied type of predictive modeling problem and there are so many different ways to think about
the performance of classification algorithms There are three things to note in the performance
summary for classification algorithms:
- **Classification accuracy** This the ratio of the number of correct predictions out of all
predictions made, often presented as a percentage where 100% is the best an algorithm
can achieve. If your data has unbalanced classes, you may want to look into the Kappa
metric which presents the same information taking the class balance into account.
- **Accuracy by class** Take note of the true-positive and false-positive rates for the
predictions for each class which can be instructive of the class breakdown for the problem
is uneven or there are more than two classes. This can help you interpret the results if
predicting one class is more important than predicting another.
- **Confusion matrix** A table showing the number of predictions for each class compared
to the number of instances that actually belong to each class. This is very useful to get
an overview of the types of mistakes the algorithm made.

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-15/steps/images/75.png)