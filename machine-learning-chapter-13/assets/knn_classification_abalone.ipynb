{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# k-nearest neighbors on the Abalone Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import sqrt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abalone Case Study as Classification\n",
        "In this section we will apply the k-Nearest Neighbors algorithm to the Abalone dataset. The\n",
        "first step is to load the dataset and convert the loaded data to numbers that we can use with\n",
        "the Euclidean distance calculation. For this we will use the helper function load csv() to load\n",
        "the file, str column to float() to convert string numbers to floats and str column to int()\n",
        "to convert the sex column (column 0) to integer values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        "\n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        "\n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will evaluate the algorithm using k-fold cross-validation with 5 folds. This means that\n",
        "4177/5 = 835.4 or just over 830 records will be in each fold. We will use the helper functions\n",
        "evaluate algorithm() to evaluate the algorithm with cross-validation and accuracy metric()\n",
        "to calculate the accuracy of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor _ in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        "\n",
        "# Calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "\tdistance = 0.0\n",
        "\tfor i in range(len(row1)-1):\n",
        "\t\tdistance += (row1[i] - row2[i])**2\n",
        "\treturn sqrt(distance)\n",
        "\n",
        "# Locate the most similar neighbors\n",
        "def get_neighbors(train, test_row, num_neighbors):\n",
        "\tdistances = list()\n",
        "\tfor train_row in train:\n",
        "\t\tdist = euclidean_distance(test_row, train_row)\n",
        "\t\tdistances.append((train_row, dist))\n",
        "\tdistances.sort(key=lambda tup: tup[1])\n",
        "\tneighbors = list()\n",
        "\tfor i in range(num_neighbors):\n",
        "\t\tneighbors.append(distances[i][0])\n",
        "\treturn neighbors\n",
        "\n",
        "# Make a prediction with neighbors\n",
        "def predict_classification(train, test_row, num_neighbors):\n",
        "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
        "\toutput_values = [row[-1] for row in neighbors]\n",
        "\tprediction = max(set(output_values), key=output_values.count)\n",
        "\treturn prediction\n",
        "\n",
        "# kNN Algorithm\n",
        "def k_nearest_neighbors(train, test, num_neighbors):\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\toutput = predict_classification(train, row, num_neighbors)\n",
        "\t\tpredictions.append(output)\n",
        "\treturn(predictions)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A value of k=5 neighbors was used to make predictions. You may experiment with larger k\n",
        "values to increase accuracy. Running the example prints the accuracy scores achieved on each\n",
        "fold and the mean of those scores. We can see that the mean accuracy is better than the\n",
        "baseline of 16%, but is quite poor in general. This is because of the large number of classes\n",
        "making accuracy a poor judge of skill on this problem. This fact, combined with the fact that\n",
        "many of the classes have few or one example also makes the problem challenging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test the kNN on the Abalone dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'abalone.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(1, len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert first column to integers\n",
        "str_column_to_int(dataset, 0)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "num_neighbors = 5\n",
        "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}