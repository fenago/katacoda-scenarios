The architectural design pattern created to deal with the problems
described previously is the circuit breaker pattern. The main idea
behind it is simple: wrap the invocation code into the command, which
will perform the invocation, and calculate the status of the remote
service. If the service is declared unreachable by the metrics used by
the command, then the next invocations are rejected immediately. After a
given time, new connections will be tried again, and, if successful, the
command will start performing invocations to the service again.

The name of the pattern was taken from the electrical circuit breaker, a
device used to protect the electrical circuit from the damage that may
result from the excess electrical current. If the current in the circuit
is too high then the circuit breaker opens, preventing the current from
flowing. In order to make the circuit operate again, the circuit breaker
has to be closed.

Owing to its archetype, the software circuit breaker has inherited the
electrical nomenclature. If the targeted service is healthy and the
invocations are forwarded to it directly, we will be talking about
closed breaker. If the health metrics are exceed, the invocations are
not performed, and the circuit breaker will be opened.

Obviously, the library that is responsible for the implementation of the
circuit breaker has to provide algorithms that decide whether the remote
service is healthy, how and when to open the circuit, and what to do if
a circuit breaker is closed. Let's discuss how Hystrix does it.

### The Hystrix circuit breaker

The following diagram presents the behavior of the Hystrix circuit
breaker:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-11/images/c8be0c04-3e1c-49ee-8ea9-200261960031.png)

During the invocation of the remote service, Hystrix checks whether the
circuit breaker is open. This decision is made based on the statistics
gathered from the recent invocations. If the percentage of failures in
the last time window is lower than the configured threshold, then the
circuit is open and the invocation is performed.

After the invocation is performed, the circuit breaker stores its result
(success/failure) in the statistics. The statistics are gathered for the
configured time window, which is further divided into the number of
buckets, with only one bucket being discarded at a time so that the data
for the given window is not discarded all at once.

What happens when the circuit is open? Firstly, the algorithm checks
whether the configured sleep time has passed. If it is the case, then
only one request is allowed to be executed. This stage of a circuit
breaker is called half-open and its purpose is to check whether the
invoked service is healthy again. If the invocation succeeds, then a
circuit breaker is opened again and the metrics are reset. If, on the
other hand, the sleep time has not exceeded or the one invocation in a
half-open state has failed, then the circuit breaker is opened again and
the sleep time is reset.

So, we now know the Hystrix circuit breaker algorithm and how it reacts
to statistics on successful and failed invocation. However, how do we
actually define failure? There are three cases when the invocation is
marked as failed. First, the configured invocation timeout has been
exceeded. Second, the client library has thrown an exception. Third, the
number of threads available for a given dependency has been exceeded.

The last point is an implementation of the bulkheading algorithm. Let's
learn more about it.

### Bulkheading

In order to prevent a situation in which one of the dependencies uses
the whole thread pool of an application, Hystrix keeps the thread pool
for each dependency. If one of the dependencies becomes latent, it will
keep all its threads busy and will reject further invocations, resulting
in an increased failure count.Such a strategy is called **bulkheading**.

This time, the nomenclature is taken from ship engineering: the hull of
the ship is divided into isolated bulkheads so that the hull damage in
one place results in only one bulkhead being filled with water.
Similarly, providing a thread pool for each of the dependencies results
in only a dedicated thread pool being used if one of the services is
misbehaving.

In complex distributed environments, it is often the case that the
application has many dependencies, each of which depends on other client
libraries. Often, such libraries are black boxes provided by a
third-party company, making them hard to debug. In addition, increasing
the number of those libraries increases the risk that one of them will
*poison* the whole application. With bulkheading, you can easily
mitigate this risk.

### Note

The state of each client can be easily tracked by the status of its
thread pool. If monitoring shows that one of the thread pools is full,
it is an indicator that it should be examined. If the underlying problem
is fixed, the thread pool will clear up and the service will continue
its operation.

The dependencies that share the same thread pool are configurable. As a
result, you are able to tune bulkheading behavior according to your
architecture. Such a configuration is done using Hystrix group
mechanism, which we will show you in the examples later in this chapter.

So, we already know that the invocation may fail or be forced to fail by
Hystrix. But, what happens in that scenario? The mechanism that is
supposed to deal with invocation failures is called **fallbacks**. Let's
learn more about it now.

### Fallbacks

Hystrix implements a fallbacks mechanism, which allows you to execute
your code whenever the failure of the invocation happens. The command
allows you to implement a fallback method, which will be executed during
the failure. The method is executed regardless of the cause of the
failureâ€”the same method will be executed in case of timeout or thread
pool overflow.

The fallback method doesn't have to be implemented. If fallback is not
implemented, the exception thrown by Hystrix will be propagated down the
stack trace.

If, on the other hand, you decide to implement the fallback, you have a
number of strategies for doing that. Let's take a look at a few
examples.

If you are using a service that is used to read a data, you can return
an empty answer in case of invocation failure. In such a scenario, no
data will be available in case of service failure. This solution hides
the underlying failure and immediately returns the response. The problem
is, obviously, that the requested data is unavailable. You can deal with
that by implementing the local cache and return the latest response in
case of failure. In this scenario, the failure will be hidden and the
data will be available. It won't be up to date for the time of failure,
but it will allow your system to continue its operation.

Let's suppose now that you are using the authorization service to decide
whether the user is authorized to perform some further operations. In
this case, you can implement the fallback, which will always return the
same response. However, what should this response be? As usual, it
depends on your use case. In some scenarios, you may want to avoid a
situation when a user who has paid for a service is unable to use it. In
this scenario, you would return the successful authorization each time.
The drawback is that a number of users will be able to use content that
they haven't paid for at the time of authorization service failure. In
other scenarios, you may need to deny authorization for all users.
Surely the temporary allow-all strategy is not suitable for the bank
application. In this case, you would have to deny the authorization for
all users.

Finally, in some scenarios, not writing the fallback is a good strategy.
Let's suppose that you are implementing an invocation that is supposed
to modify some data as a part of transactional operations. In this
scenario, the propagated exception is the strategy that we want: the
whole operation will be stopped, and the exception will be propagated to
the transaction manager, which will roll back the transaction.

In this section, we have only hinted at a number of possible fallback
implementation strategies. As you may have noticed, the specific
implementation (or lack of) depends directly on your service's business
requirements. The key point to remember is that Hystrix won't allow the
network failure to compromise the behavior of your application, and if a
failure occurs it will allow you to deal with it using the fallback
mechanism.

### The whole algorithm

Finally, we are ready to sum up the behavior of the Hystrix library:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-11/images/b7a43fc4-7329-4d5b-8966-bd369ffed6ec.png)

At the beginning, the user constructs the command and starts its
execution. Hystrix checks whether the circuit breaker associated with
this command is closed. If the circuit breaker is open, then the
invocation will be rejected immediately and the fallback will be
executed (if implemented). If the circuit breaker is closed, then the
thread-pool is checked. If there are no available threads in the
thread-pool, then the invocation fails; optionally, the fallback is
executed and the failure is reported to the circuit breaker. If, on the
other hand, there are threads available, then the invocation starts. If
the invocation misses its timeout, then the failure is reported to the
circuit breaker and the optional fallback is executed.

### Note

In this scenario, the thread may be blocked. Hystrix will time it out,
but will have to wait for the client library to *return the thread*. If
the invocation finishes and fails, then the failure is reported to the
circuit breaker and optionally the fallback is executed.

Finally, if the execution succeeds, then the success is reported to the
circuit breaker and the response is returned as the result of the
command execution.

You have already learned the basics of the Hystrix's circuit breaker
implementation. Now it is time to learn its basic API, which we will use
later in this chapter. Let's do it now.
