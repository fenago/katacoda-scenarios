In the first chapter, when we were explaining why you may be considering
implementing the microservice architecture in your applications, we
mentioned the challenges that are being currently faced by application
developers and architects. 

One of the key tools that may enable us to deal with providing software
in a way that enables us to meet those challenges is automation. As we
covered in the preceding chapter, OpenShift enables us to automate
infrastructure provisioning. However, we need more than that. 

We will also like to automate the process of deploying software into
production. Ideally, we will like to have tools that will enable us to
release software immediately. OpenShift provides such a tool in the form
of the build `pipeline`. Let's introduce the rationale behind
this concept.

Let's start with CI.

### Continuous integration

As a developer, you know too well what the development of projects looks
like. There are many developers working on different functionalities,
which they contribute to the same repository. Contributions from all the
developers have to be integrated into the code repository so that stable
code is created. After that, the code can be published into the
production environment.

This sounds simple, but if you don't create an organized order according
to which this process is executed, you will quickly end up with a huge
mess. If the developers will integrate rarely, they are asking for
problems. Their repositories will be highly diverged, and the
application's functionality will be scattered between their
repositories. As a result, during the development, there will be no
*current state* source repository, and we will have no information about
the state of an application. The new version of an application will
emerge during the time people decide to push their contribution to the
main code (which will presumably happen the day before the release). The
process of integration at this point will be painful, where incompatible
contributions are being discovered, and errors will emerge. Such a
situation was described in the past as *integration hell*. 

Owing to the preceding problems, it became clear that it will be a good
idea to integrate code frequently. The methodology that advocates such a
behavior and, more importantly, gives hints on how to do it, is called
CI.

Obviously, pushing the code frequently to the repository is not helping
us much. At each commit, we need to make sure that the current version
of the code at least compiles, and passes unit and integration tests.
This is by no means a comprehensive list: to declare your code
correctly, you may also need automatic code inspections or code reviews
to name a few. 

In order for this process to be executed consistently, it has to be
automated and executed each time the user wants to make the change to
the code. Also, developers are supposed to integrate their code
frequently, with each logical functionality developed, and are supposed
to fix any errors that appear as soon as possible.

If this procedure is observed, this will lead to a number of benefits:

-   Problems are detected quickly. As the result, their source can be
    debugged and fixed quickly.
-   The current version of the application is always present—it is the
    result of the last successful build. At each point, we can tell the
    status of the application, how it works, and what functionalities
    have been currently implemented.
-   The automated process works as a trigger for quality control. The
    build is guaranteed to be run and be reproducible. 

### Continuous deployment

Continuous Integration ensures continuous builds of source code. It
demands that fixes are pushed often and provides instant feedback to the
developers. What if we extend this notion and configure our build
infrastructure so that it will ensure that our services will be built
and deployed automatically? 

Such an approach, which is an extension of CI, is called Continuous
Deployment. To implement it, we will need to automate the release
process also. This means that we will have to keep all the resources
that are needed to release the software to the given environment, such
as environment properties or configuration scripts. 

As a reward, we will be able to obtain reliable and repeatable releases.
First of all, as the release process is no longer manual, all the magic
is taken away from the release process. The release is executed by the
release script using environment properties, which are both parts of the
versioned build configuration. Those files are the one source-of-truth
regarding the build process. As a result, if an error occurs during the
build, those scripts have to be fixed. There is no place for manual
patches or ad hoc fixes. Also, builds happen often, so configuration
bugs will have an opportunity to occur and be fixed. On the other hand,
after builds and releases start to work correctly, each next correct
build adds more confidence in the release process. As a result, the
release becomes a well-tested and an automated event.

### Note

Such an approach changes the way the team works by changing the speed at
which features are developed. With CD, you are not releasing the
software in large chunks to the client. Instead, small functionalities
are released often and are immediately visible to the client.

This is the expected behavior for a number of reasons. First, customers
will like to respond to client demand as quickly as possible. Having the
tool that enables them to do that will be a big market advantage for the
customer. However, there is more to it: because new functionalities are
released often, they are visible to the customer immediately. As a
result, a customer can immediately assess the actually implemented
functionality. This creates an efficient feedback loop between the
developers and the customers, which allow for faster convergence to the
functionality actually expected by the client.

### Deployment pipeline

The process of automatic delivery is implemented using a
`pipeline`. A `pipeline` is a chain of steps that
takes the source code as its input and provides a working application on
it's output.

The goal of the `pipeline` is to make sure that the source
code is ready to be deployed in production. As a result,
a `pipeline` should be able to catch errors as soon as
possible and provide feedback to the developers immediately. 

Also, because the final product is the released application,
a `pipeline` should automate the release process so that it is
run the same in all environments.

Although a `pipeline` is a configurable script and its direct
operation depends on your concrete environment, there are a number
of common steps that are executed in the deployment
`pipeline`: commit, build, automatic tests, manual tests,
release, and so on.
