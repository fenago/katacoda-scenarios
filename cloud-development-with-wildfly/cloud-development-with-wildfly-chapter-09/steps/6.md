As we mentioned, the source-to-image build needs a builder image and you
have to provide it each time when you are configuring such a build. The
builder images contain scripts that are responsible for assembling and
running the application. The assembling scripts will be run in phase 3
of the build algorithm, and the run script will be used as the start
command of the resulting Docker image. During the build, the layer that
contains the runnable application will be added on top of the builder
image, the run script will be set as the image starting command, and the
resulting image will be committed.

We know the basics of source-to-image builds, so now we can explain what
we did when deploying our application in the last chapters. Let's start
with the following command that we have invoked before running any
builds:

```
oc create -f https://raw.githubusercontent.com/wildfly-swarm/sti-wildflyswarm/master/1.0/wildflyswarm-sti-all.json
```

The preceding command is responsible for including a YAML object file
into our cluster. The main object created by this script is the Docker
build configuration. If we examine our cluster using command-line tools,
we will find that the new build config is created:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/aa71ae40-788e-4a63-bc70-0264770be132.png)

This is the build config for our builder image. We may now examine
builds in the Web Console. We will be able to see that the build based
on `wildfyswarm-10-centos7` config has already been executed:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/48d4f51a-c5bd-4cbb-a699-fdb58e03c245.png)

After the execution of the first command, the builder image was created
and stored in the cluster. We can confirm this by navigating
to **`Build`** | **`Images`** in the web console:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/b183703d-24ac-4a6f-99f8-9818913fa473.png)

As you will have noticed in the preceding screenshot, we have a new
image, **`wildflyswarm-10-centos7`**, available in the cluster. An
important thing to note here is that these images have been described
as`ImageStreams`. What does that
actually mean? `ImageStream`, as its name suggests, is an
object that represents a stream of related objects. In our scenario, the
`ImageStream` contains all images that are the result of the
build of the builder image.

### Note

We created the BuildConfig for the builder image. The source for this
image can change; if that happens, OpenShift will create a new version
of this image and add it to the`ImageStream`.

The images in the stream can be tagged, and there is always the latest
tag, which represents the latest image in the stream. 

Let's now examine the `new-app` command that we have used
before:

```
oc new-app wildflyswarm-10-centos7~https://github.com/PacktPublishing/Hands-On-Cloud-Development-with-WildFly.git (...)
```

We are now ready to explain what the `new-app` syntax means.
It has two parts separated by a tilde. The first one is the name of the
builder-image stream. The second one is the GitHub repository from which
the application will be built. 

After we know the internals of the source-to-image build, we can run the
build again and examine the build log.

First, we have to remove the`pricing-service` that we have
deployed previously:

```
oc delete all -l app=pricing-service
```

After that, we are ready to execute the `new-app` command and
use web console to inspect the log:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/b5e539b9-2038-4792-a753-f48a8df2b3fc.png)

Oops! We have to download all the dependencies. This fact will result in
build taking a substantial amount of time:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/8c2ed756-893b-468b-90d5-270546da7e8a.png)

This was just a first build. So, what will happen when we run the build
for the second time? You can use the web console to force the second
build and inspect the log to verify that the dependencies are downloaded
again.

This is a serious inconvenience, as it results in much longer build
types. Can we do something about it? Yes, we can use incremental builds.

The incremental build is a feature of the source-to-image build, which
extracts the build artifacts from the previously created image and uses
them to build the next one.

### Note

Our builder image uses the Maven plugin to build a Swarm application, so
the artifacts that are being downloaded are the Maven dependency JARs.
Usually, different build tools and different types of the artifact will
be used. As a result, the specific type of incremental build has to be
implemented by the image provider.

In the case of a Swarm builder image, the Maven artifacts are being
extracted from the last image and placed in the Maven repo of the new
one. As a result, artifacts that are being used many times have to be
downloaded only once. Furthermore, in order to decrease the time spent
downloading the JARs, you can use a Maven mirror.

OK. However, how can we turn the incremental build on? We have to edit
the YAML of our build. Let's use the web console for that. We have to
select the `pricing-service` build and navigate
to **`Actions`** | **`Edit YAML`** in the top-right corner of the
screen. The YAML has to be edited in the following way:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/e96a902c-c074-45db-ba85-6b668707cde2.png)

As you will have noticed in the preceding screenshot, we found the
`sourceStrategy` section of the build config and added an
incremental property with a value set to `true`. Let's run our
build again to see what happens.

In our new build log, we can see two optimistic lines: 

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/8954c309-1888-4e87-a0b1-ac3c3b2ba507.png)

The first optimistic line is at the beginning where Maven informs us
that the artifacts are being restored and the second one is at the end:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/ded5494a-8d7d-47ea-b622-b873fd3537ce.png)

The build has taken only`16.347` seconds, not much longer than
the standalone Maven build.

### Configuring environment variables

When we were deploying our services, we provided an environment
variables script for catalog and `pricing-services`that needs
to interact with our database. Processing this configuration file is
also the responsibility of the source-to-image build. If a user wants to
provide environment properties to the build, they have to create a
`.s2i` directory in the root of the service's GitHub
repository and create an environment file that will contain a list of
key-value pairs.

For example, let's recall the configuration file for
the`pricing-service`:

```
POSTGRESQL_HOST=pricing-service.petstore.svc
POSTGRESQL_USER=pricing
POSTGRESQL_PASSWORD=pricing
POSTGRESQL_SCHEMA=pricingdb
```

Properties set in this file will be available as environment variables
during the image build and during its execution.

### The whole source-to-image algorithm

After covering the specifics of the source-to-image build operation,
let's recap the steps in Swarm's `s2i` build:

1.  The container on which the build will take place is created from the
    builder image.
2.  The sources of an application are injected into the container.
3.  If incremental builds are enabled, the Maven artifacts will be
    restored from the previous build image.
4.  If provided, environment variables are set.
5.  The assembly script, provided by the image creator, is executed.
6.  The image is committed with the start command set to the run script
    provided by the image creator.

A developer who will like to build their applications using the
source-to-image build has to provide the name of the builder image and
the source code of an application. A developer can enable the
incremental build and provide environment variables.

### Source-to-image summary

Now that we have covered how the source-to-image build works internally,
it's time to look at it from a wider perspective.

The source-to-image build is another tool provided by OpenShift that
abstracts away the details of the Kubernetes cluster, providing a simple
interface for the developer. The role of the developer is to provide the
source code and the name of the image that will be used to build it. It
is the responsibility of the image creator to assemble the Docker image
that will be deployed on the cluster.

Again, this leads to the separation of concerns—the builder image
provider is responsible for assembling source in an optimal way and the
details of those optimizations don't have to be known by the developer.

The performance implications of builds resulting from the build
architecture are as follows. The libraries that are needed to perform
the build and create the runnable container are located in the builder
image, which is created once (and later only updated) inside the
cluster. The artifacts that are being downloaded during the build can be
restored from previous builds if the incremental build is enabled. Owing
to that, the dependencies of the application can be downloaded only once
and later reused. This leads to a very fast build time. As you may
remember, the build of our pricing service took only about 16 seconds,
which is only a few seconds more than standalone Maven builds on
a modern workstation.

Moreover, the reproducibility, which is one of the constant benefits of
using Docker, holds for builder images also. All the builds are
performed using exactly the same image. As a result, it is guaranteed
that the build result will be the same on all of your environments.

In addition, since builder images are just standard Docker containers
and the explicit builder contract allows tool creators to write builder
images easily, there is an wide variaty of Docker builder images that
you can use. You, as a developer, already have access to a wide variety
of builder images dedicated to number of development tools.

In the end, a source-to-image build tool is a tool that represents the
core of the OpenShift philosophy. It provides a simple developer
interface, which abstracts away the cluster internals, and under the
hood it implements the an optimized build process.

### The developer view

Till now, we have explained in detail how the source-to-image build
builds an image based on your code. The new-app command does not just
create the build though. As you remember, after its execution, we were
able to test the working application. Clearly, the build and image are
not the only product of the command. 

Apart from the`BuildConfiguration`, the new-app command
creates the`DeploymentConfiguration` (that we described in
[Chapter
6](https://subscription.packtpub.com/book/web_development/9781786462374/6),
*Deploying Applications on the Cloud with OpenShift*) and
an`ImageStream` for our application.

Let's take a look at the created objects in the following diagram:

![](https://github.com/athertahir/katacoda-scenarios/raw/master/cloud-development-with-wildfly/cloud-development-with-wildfly-chapter-09/images/ec878c9d-7a43-482e-83cd-f65d14bdf3c7.png)

In the preceding diagram, the objects related to the builder image are
colored red, build-related objects are colored blue, and
deployment-related objects are colored green. The build is triggered by
a developer by pushing changes to GitHub. It results in the creation of
the build objects. If the build is successful, the image is pushed to
the image stream. This further triggers the deployment of the
application, which, if successful, results in the creation of
application services.

The important thing to note is that, in the simplest scenario, a
developer may be responsible only for pushing the changes to the
repository—in other words, programming and their changes will be
propagated to the cluster.

That's nice again, but, in some scenarios, we will like to have more
than that: a full CD `pipeline` with integration tests,
checking the deployed application, or staging the changes in different
environments. As we hinted earlier, we can integrate an OpenShift
cluster with Jenkins to use its full power to implement the CD
`pipeline` for our services. Let's learn how to do it.
